### 强化学习第二章与算法基础课



#### Markov决策过程

​	这是强化学习**最经典、最重要的数学模型**

##### 基础概念

1. 状态空间S，环境状态的集合
2. 观测空间O，agent观测环境的观测集合
3. 动作空间A， 动作的集合
4. 奖励空间R， 根据当前状态s与动作a，给予agent奖励的集合

##### 轨道

​	离散化agent/环境接口可以用轨道表示，这是一个回合循环

##### Markov性

​	指当前奖励 R 和下一状态 S‘ 仅仅依赖当前的状态 S 和动作 A

##### 动力

​	本质为一个概率函数，指当前状态S采取动作A后，进入奖励和下一状态的概率大小

##### 状态转移概率

​	一个状态采取动作后进入另一状态的概率

##### 期望奖励

​	在给定条件下，奖励的期望数值

##### 策略

​	当前状态下，采取某种动作的概率

##### 回报

​	步骤t之后，终止状态之前，奖励的和

##### 折扣

​	计算回报时，每一步奖励的权重

##### 价值函数

- 状态价值函数

  从状态s开始，采用策略π，的期望回报

- 动作价值函数

  从状态s和动作a之后，采用策略π的期望回报



#### 算法基础课

##### 奇奇怪怪的bug

​		今天在刷题的时候，有意尝试了一些奇葩的写法，做了个大死，试出来了一些不容易注意到的细节

1. **无符号整数没有负值**，所以不要拿来判断数组下标，大量直觉上不会为负的参数大都是无符号整数，string.substr(int pos, int len)中的pos就是无符号整数
2. **while()循环的条件每轮循环都会执行一次**，所以不要拿来初始化一个变量

##### 算法学习

​	从跳台阶问题中学会了**手画递归树**的重要性，可以**正向画递归树**，也可以**反向画递归树**

